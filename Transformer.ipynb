{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qp33vYwSO70Y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "import spacy\n"
      ],
      "metadata": {
        "id": "woWox7zBPCKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.legacy.datasets import Multi30k"
      ],
      "metadata": {
        "id": "xi7kfZvrPFDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "brR7gF9YPGi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3u5O60rx64n",
        "outputId": "4e0218bd-a5c0-44df-e563-ccfcd4d286ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting de_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-py3-none-any.whl size=14907055 sha256=47b40b1f1b5469dc48a0dac51759d0a844f94919dc1a01d69006ecc7cc3e613d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r0f6tjgh/wheels/00/66/69/cb6c921610087d2cab339062345098e30a5ceb665360e7b32a\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_en = spacy.load(\"en_core_web_sm\")\n",
        "spacy_ger = spacy.load(\"de_core_news_sm\")"
      ],
      "metadata": {
        "id": "GfaC8L8OPHxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def en_token(text):\n",
        "    return [token.text for token in spacy_en.tokenizer(text)]\n",
        "def ger_token(text):\n",
        "    return [token.text for token in spacy_ger.tokenizer(text)]\n",
        "eng_field = Field(tokenize=en_token,lower=True, init_token=\"<sos>\",\n",
        "                    eos_token=\"<eos>\",\n",
        "                    batch_first=True\n",
        "                 )\n",
        "ger_field = Field(tokenize=ger_token,lower=True, init_token=\"<sos>\",\n",
        "                  eos_token=\"<eos>\",\n",
        "                  batch_first=True\n",
        "                 )\n",
        "train,val,test = Multi30k.splits(exts=(\".de\",\".en\"),fields=(ger_field,eng_field))\n",
        "eng_field.build_vocab(train,max_size=10000,min_freq=2)\n",
        "ger_field.build_vocab(train,max_size=10000,min_freq=2)"
      ],
      "metadata": {
        "id": "E8cE4IP0PJdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "OYjKyZS3PLQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
        "        (train,val,test),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        sort_within_batch=True,\n",
        "        sort_key = lambda x: len(x.src),\n",
        "        device=device\n",
        ")"
      ],
      "metadata": {
        "id": "ZHxHdCJMPMoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mgVijQHKc2TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHead_Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_head, device):\n",
        "        super(MultiHead_Attention,self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_head = n_head\n",
        "        self.head_dim = hidden_dim // n_head\n",
        "        self.q_fc = nn.Linear(hidden_dim,hidden_dim)\n",
        "        self.k_fc = nn.Linear(hidden_dim,hidden_dim)\n",
        "        self.v_fc = nn.Linear(hidden_dim,hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim,hidden_dim)\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "    def forward(self,query,key,value,mask):\n",
        "        print(f\"input multi shape {query.shape}\")\n",
        "        batch = query.shape[0]\n",
        "        query_len,key_len,value_len = query.shape[1],key.shape[1],value.shape[1]\n",
        "        Q = self.q_fc(query)\n",
        "        K = self.k_fc(key)\n",
        "        V = self.v_fc(value)\n",
        "        print(f\"query fully connected {Q.shape}\")\n",
        "        Q  = Q.view(batch,self.n_head,query_len,self.head_dim)\n",
        "        K = K.view(batch,self.n_head,key_len,self.head_dim)\n",
        "        V = V.view(batch,self.n_head,value_len,self.head_dim)\n",
        "        print(f\"Q view(batch,self.n_head,query_len,self.head_dim) {Q.shape}\")\n",
        "        energy = torch.einsum(\"bnqd,bnkd->bnqk\",Q,K)/ self.scale\n",
        "        print(f\"energy bnqk shape {energy.shape} \")\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask==0,-1e10)\n",
        "\n",
        "        attention = torch.softmax(energy,dim=-1)\n",
        "        value_attn = torch.matmul(attention,V)\n",
        "        print(f\"matmul with value {value_attn.shape}\")\n",
        "                \n",
        "        x = value_attn.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        x = value_attn.view(batch,query_len,self.hidden_dim)\n",
        "        x = self.fc(x)\n",
        "        print(f\"out multi shape {x.shape}\")\n",
        "        return x, attention"
      ],
      "metadata": {
        "id": "m0gFH6pcPOow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# source mask torch.Size([16, 1, 1, 14])"
      ],
      "metadata": {
        "id": "3D-H_80TVZvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Positon_wise_feed(nn.Module):\n",
        "    def __init__(self,hidden_dim,pf_dim,dropout):\n",
        "        super(Positon_wise_feed,self).__init__()\n",
        "        self.hid_to_pf = nn.Linear(hidden_dim,pf_dim)\n",
        "        self.pf_to_hid = nn.Linear(pf_dim,hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self,x):\n",
        "        x = self.dropout(self.hid_to_pf(x))\n",
        "        x = self.pf_to_hid(x)\n",
        "        return x\n",
        "        "
      ],
      "metadata": {
        "id": "8MHUwoHcPTND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_layer(nn.Module):\n",
        "    def __init__(self,hidden,n_head,pf_dim,dropout,device):\n",
        "        super(Encoder_layer,self).__init__()\n",
        "        self.multihead = MultiHead_Attention(hidden,n_head,device)\n",
        "        self.posi_feed = Positon_wise_feed(hidden,pf_dim,dropout)\n",
        "        self.Norm_multi = nn.LayerNorm(hidden)\n",
        "        self.Norm_posifeed = nn.LayerNorm(hidden)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self,query,key,value,mask):\n",
        "        x,_ = self.multihead(query,key,value,mask)\n",
        "        x_mul = self.Norm_multi(query+self.dropout(x))\n",
        "        x = self.posi_feed(x_mul)\n",
        "        x = self.Norm_posifeed(x_mul+x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "QoGlebMYTLFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self,input_vocab,hidden,\n",
        "                 n_head,n_layers,pf_dim,dropout,max_length,device):\n",
        "        super(Encoder,self).__init__()\n",
        "        self.embedding = nn.Embedding(input_vocab,hidden)\n",
        "        self.position_encoding = nn.Embedding(max_length,hidden)\n",
        "        self.encoder_layer =  nn.ModuleList([Encoder_layer\n",
        "                 (hidden,n_head,pf_dim,dropout,device) for i in range(n_layers)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden])).to(device)\n",
        "    def forward(self,x,maks):\n",
        "        seq_len = x.shape[1]\n",
        "        batch_size = x.shape[0]\n",
        "        position = torch.arange(0,seq_len).unsqueeze(0).repeat(batch_size,1).to(device)\n",
        "        src = self.dropout((self.embedding(x)*(self.scale))+self.position_encoding(position))\n",
        "        for layer in self.encoder_layer:\n",
        "            src = layer(src,src,src,maks)\n",
        "        return src"
      ],
      "metadata": {
        "id": "1WuA7pd9TlPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder_layer(nn.Module):\n",
        "    def __init__(self,hidden,pf_dim,n_head,dropout,device):\n",
        "        super(Decoder_layer,self).__init__()\n",
        "        self.mask_multihead = MultiHead_Attention(hidden,n_head,device)\n",
        "        self.Norm_mask = nn.LayerNorm(hidden)\n",
        "        self.multihead= MultiHead_Attention(hidden,n_head,device)\n",
        "        self.Norm_multi = nn.LayerNorm(hidden)\n",
        "        self.feed = Positon_wise_feed(hidden,pf_dim,dropout)\n",
        "        self.Norm_feed = nn.LayerNorm(hidden)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self,query,key,value,key_encoder,value_encoder,src_mask,trg_mask):\n",
        "        x,_ = self.mask_multihead(query,key,value,trg_mask)\n",
        "        x_norm = self.Norm_mask(query+self.dropout(x))\n",
        "        x,_ = self.multihead(query,key_encoder,value_encoder,src_mask)\n",
        "        x_multi_norm = self.Norm_multi(self.dropout(x)+x_norm)\n",
        "        x = self.feed(x_multi_norm)\n",
        "        x_fedd_norm = self.Norm_feed(self.dropout(x)+x_multi_norm)\n",
        "        return x_fedd_norm"
      ],
      "metadata": {
        "id": "WvEKPaVHTRlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,input_vocab,hidden,n_layer,pf_hidden,n_head,max_length,dropout,device):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.embedding_input = nn.Embedding(input_vocab,hidden)\n",
        "        self.embedding_position = nn.Embedding(max_length,hidden)\n",
        "        self.layer = nn.ModuleList([Decoder_layer(hidden,pf_hidden,n_head,dropout,device) \n",
        "                                   for _ in range(n_layer)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.device = device\n",
        "        self.fc = nn.Linear(hidden,input_vocab)\n",
        "        # self.softmax = nn.Softmax(dim=2)\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden])).to(device)\n",
        "    def forward(self,trg_value,key_encoder,value_encoder,src_mask,trg_mask):\n",
        "        seq_len = trg_value.shape[1]\n",
        "        batch = trg_value.shape[0]\n",
        "        position = torch.arange(0,seq_len).unsqueeze(0).repeat(batch,1).to(self.device)\n",
        "        x = self.dropout(self.embedding_input(trg_value)*self.scale) +self.embedding_position(position)\n",
        "        for layer in self.layer:\n",
        "            x = layer(x,x,x,key_encoder,value_encoder,src_mask,trg_mask)\n",
        "        output1 = self.fc(x)\n",
        "        # output2 = self.softmax(output1)\n",
        "        return output1\n",
        "        \n",
        "        "
      ],
      "metadata": {
        "id": "AA3IAbneTUTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,encoder,decoder,src_pad,trg_pad,device):\n",
        "        super(Seq2Seq,self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad = src_pad\n",
        "        self.trg_pad = trg_pad\n",
        "        self.device = device\n",
        "    def make_src_mask(self,x):\n",
        "        src = (x!=self.src_pad).unsqueeze(1).unsqueeze(2)\n",
        "        return src\n",
        "    def make_trg_mask(self,x):\n",
        "        trg = (x!=self.trg_pad).unsqueeze(1).unsqueeze(2)\n",
        "        # trg1 = trg.permute(3,1,2,0)\n",
        "        trg_len = x.shape[1]\n",
        "        sub_mask = torch.tril(torch.ones((trg_len,trg_len),device=self.device)).bool()\n",
        "\n",
        "        out =   trg & sub_mask\n",
        "        return out\n",
        "    def forward(self,src,target):\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(target)\n",
        "       \n",
        "        encoder_model = self.encoder(src,src_mask)\n",
        "        decoder = self.decoder(target,encoder_model,encoder_model,src_mask,trg_mask)\n",
        "        \n",
        "        return decoder"
      ],
      "metadata": {
        "id": "BPXgFOG-TXwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden = 512\n",
        "pf_dim = 2048\n",
        "ger_vocab = len(ger_field.vocab)\n",
        "eng_vocab = len(eng_field.vocab)\n",
        "dropout = 0.2\n",
        "n_layer_encoder = 4\n",
        "n_layer_decoder = 2\n",
        "n_head = 8\n",
        "src_pad = ger_field.vocab.stoi[ger_field.pad_token]\n",
        "trg_pad = eng_field.vocab.stoi[eng_field.pad_token]\n",
        "max_length = 100"
      ],
      "metadata": {
        "id": "AWgTcjacWV4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(ger_vocab,hidden,n_head,n_layer_encoder,pf_dim,dropout,max_length,device)\n",
        "decoder = Decoder(eng_vocab,hidden,n_layer_decoder,pf_dim,n_head,max_length,dropout,device)\n"
      ],
      "metadata": {
        "id": "1_4YJotQZ-PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Seq2Seq(encoder,decoder,src_pad, trg_pad, device).to(device)"
      ],
      "metadata": {
        "id": "ZjstzR0nvcOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss(ignore_index=trg_pad)\n",
        "lr = 0.0001\n",
        "optim = torch.optim.Adam(transformer.parameters(),lr)\n",
        "num_epoch = 1"
      ],
      "metadata": {
        "id": "MvPNcb2X1suT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "TgTSwD4O3wvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip = 1"
      ],
      "metadata": {
        "id": "9Z1H9FeCOWfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "  loop = tqdm(enumerate(train_iter),total=len(train_iter),leave=False)\n",
        "  for inx,data in loop:\n",
        "    src = (data.src).to(device)\n",
        "    trg = (data.trg).to(device)\n",
        "    print(f\"trg shape is {trg.shape}\")\n",
        "    optim.zero_grad()\n",
        "    output = transformer(src,trg[:,:-1])\n",
        "\n",
        "    output_dim = output.shape[-1]\n",
        "    output1 = output.contiguous().view(-1, output_dim)\n",
        "    target = trg[:,1:].contiguous().view(-1)\n",
        "    los = loss(output1,target)\n",
        "    los.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(transformer.parameters(), clip)\n",
        "    optim.step()\n",
        "    loop.set_description(f\"Epoch [{i}/{num_epoch}]\")\n",
        "    loop.set_postfix(loss=los.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d1CtkdxK3xv8",
        "outputId": "a3c59db5-46e0-4c3e-f424-3a77e5088865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1813 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trg shape is torch.Size([16, 26])\n",
            "input multi shape torch.Size([16, 22, 512])\n",
            "query fully connected torch.Size([16, 22, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 22, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 22, 22]) \n",
            "matmul with value torch.Size([16, 8, 22, 64])\n",
            "out multi shape torch.Size([16, 22, 512])\n",
            "input multi shape torch.Size([16, 22, 512])\n",
            "query fully connected torch.Size([16, 22, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 22, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 22, 22]) \n",
            "matmul with value torch.Size([16, 8, 22, 64])\n",
            "out multi shape torch.Size([16, 22, 512])\n",
            "input multi shape torch.Size([16, 22, 512])\n",
            "query fully connected torch.Size([16, 22, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 22, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 22, 22]) \n",
            "matmul with value torch.Size([16, 8, 22, 64])\n",
            "out multi shape torch.Size([16, 22, 512])\n",
            "input multi shape torch.Size([16, 22, 512])\n",
            "query fully connected torch.Size([16, 22, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 22, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 22, 22]) \n",
            "matmul with value torch.Size([16, 8, 22, 64])\n",
            "out multi shape torch.Size([16, 22, 512])\n",
            "input multi shape torch.Size([16, 25, 512])\n",
            "query fully connected torch.Size([16, 25, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 25, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 25, 25]) \n",
            "matmul with value torch.Size([16, 8, 25, 64])\n",
            "out multi shape torch.Size([16, 25, 512])\n",
            "input multi shape torch.Size([16, 25, 512])\n",
            "query fully connected torch.Size([16, 25, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 25, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 25, 22]) \n",
            "matmul with value torch.Size([16, 8, 25, 64])\n",
            "out multi shape torch.Size([16, 25, 512])\n",
            "input multi shape torch.Size([16, 25, 512])\n",
            "query fully connected torch.Size([16, 25, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 25, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 25, 25]) \n",
            "matmul with value torch.Size([16, 8, 25, 64])\n",
            "out multi shape torch.Size([16, 25, 512])\n",
            "input multi shape torch.Size([16, 25, 512])\n",
            "query fully connected torch.Size([16, 25, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 25, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 25, 22]) \n",
            "matmul with value torch.Size([16, 8, 25, 64])\n",
            "out multi shape torch.Size([16, 25, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [0/1]:   0%|          | 1/1813 [00:02<1:04:53,  2.15s/it, loss=8.8]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trg shape is torch.Size([16, 18])\n",
            "input multi shape torch.Size([16, 13, 512])\n",
            "query fully connected torch.Size([16, 13, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 13, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 13, 13]) \n",
            "matmul with value torch.Size([16, 8, 13, 64])\n",
            "out multi shape torch.Size([16, 13, 512])\n",
            "input multi shape torch.Size([16, 13, 512])\n",
            "query fully connected torch.Size([16, 13, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 13, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 13, 13]) \n",
            "matmul with value torch.Size([16, 8, 13, 64])\n",
            "out multi shape torch.Size([16, 13, 512])\n",
            "input multi shape torch.Size([16, 13, 512])\n",
            "query fully connected torch.Size([16, 13, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 13, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 13, 13]) \n",
            "matmul with value torch.Size([16, 8, 13, 64])\n",
            "out multi shape torch.Size([16, 13, 512])\n",
            "input multi shape torch.Size([16, 13, 512])\n",
            "query fully connected torch.Size([16, 13, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 13, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 13, 13]) \n",
            "matmul with value torch.Size([16, 8, 13, 64])\n",
            "out multi shape torch.Size([16, 13, 512])\n",
            "input multi shape torch.Size([16, 17, 512])\n",
            "query fully connected torch.Size([16, 17, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 17, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 17, 17]) \n",
            "matmul with value torch.Size([16, 8, 17, 64])\n",
            "out multi shape torch.Size([16, 17, 512])\n",
            "input multi shape torch.Size([16, 17, 512])\n",
            "query fully connected torch.Size([16, 17, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 17, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 17, 13]) \n",
            "matmul with value torch.Size([16, 8, 17, 64])\n",
            "out multi shape torch.Size([16, 17, 512])\n",
            "input multi shape torch.Size([16, 17, 512])\n",
            "query fully connected torch.Size([16, 17, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 17, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 17, 17]) \n",
            "matmul with value torch.Size([16, 8, 17, 64])\n",
            "out multi shape torch.Size([16, 17, 512])\n",
            "input multi shape torch.Size([16, 17, 512])\n",
            "query fully connected torch.Size([16, 17, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 17, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 17, 13]) \n",
            "matmul with value torch.Size([16, 8, 17, 64])\n",
            "out multi shape torch.Size([16, 17, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [0/1]:   0%|          | 2/1813 [00:03<50:47,  1.68s/it, loss=8.57]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trg shape is torch.Size([16, 13])\n",
            "input multi shape torch.Size([16, 11, 512])\n",
            "query fully connected torch.Size([16, 11, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 11, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 11, 11]) \n",
            "matmul with value torch.Size([16, 8, 11, 64])\n",
            "out multi shape torch.Size([16, 11, 512])\n",
            "input multi shape torch.Size([16, 11, 512])\n",
            "query fully connected torch.Size([16, 11, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 11, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 11, 11]) \n",
            "matmul with value torch.Size([16, 8, 11, 64])\n",
            "out multi shape torch.Size([16, 11, 512])\n",
            "input multi shape torch.Size([16, 11, 512])\n",
            "query fully connected torch.Size([16, 11, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 11, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 11, 11]) \n",
            "matmul with value torch.Size([16, 8, 11, 64])\n",
            "out multi shape torch.Size([16, 11, 512])\n",
            "input multi shape torch.Size([16, 11, 512])\n",
            "query fully connected torch.Size([16, 11, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 11, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 11, 11]) \n",
            "matmul with value torch.Size([16, 8, 11, 64])\n",
            "out multi shape torch.Size([16, 11, 512])\n",
            "input multi shape torch.Size([16, 12, 512])\n",
            "query fully connected torch.Size([16, 12, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 12, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 12, 12]) \n",
            "matmul with value torch.Size([16, 8, 12, 64])\n",
            "out multi shape torch.Size([16, 12, 512])\n",
            "input multi shape torch.Size([16, 12, 512])\n",
            "query fully connected torch.Size([16, 12, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 12, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 12, 11]) \n",
            "matmul with value torch.Size([16, 8, 12, 64])\n",
            "out multi shape torch.Size([16, 12, 512])\n",
            "input multi shape torch.Size([16, 12, 512])\n",
            "query fully connected torch.Size([16, 12, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 12, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 12, 12]) \n",
            "matmul with value torch.Size([16, 8, 12, 64])\n",
            "out multi shape torch.Size([16, 12, 512])\n",
            "input multi shape torch.Size([16, 12, 512])\n",
            "query fully connected torch.Size([16, 12, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 12, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 12, 11]) \n",
            "matmul with value torch.Size([16, 8, 12, 64])\n",
            "out multi shape torch.Size([16, 12, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [0/1]:   0%|          | 3/1813 [00:04<43:10,  1.43s/it, loss=8.31]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trg shape is torch.Size([16, 25])\n",
            "input multi shape torch.Size([16, 21, 512])\n",
            "query fully connected torch.Size([16, 21, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 21, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 21, 21]) \n",
            "matmul with value torch.Size([16, 8, 21, 64])\n",
            "out multi shape torch.Size([16, 21, 512])\n",
            "input multi shape torch.Size([16, 21, 512])\n",
            "query fully connected torch.Size([16, 21, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 21, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 21, 21]) \n",
            "matmul with value torch.Size([16, 8, 21, 64])\n",
            "out multi shape torch.Size([16, 21, 512])\n",
            "input multi shape torch.Size([16, 21, 512])\n",
            "query fully connected torch.Size([16, 21, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 21, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 21, 21]) \n",
            "matmul with value torch.Size([16, 8, 21, 64])\n",
            "out multi shape torch.Size([16, 21, 512])\n",
            "input multi shape torch.Size([16, 21, 512])\n",
            "query fully connected torch.Size([16, 21, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 21, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 21, 21]) \n",
            "matmul with value torch.Size([16, 8, 21, 64])\n",
            "out multi shape torch.Size([16, 21, 512])\n",
            "input multi shape torch.Size([16, 24, 512])\n",
            "query fully connected torch.Size([16, 24, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 24, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 24, 24]) \n",
            "matmul with value torch.Size([16, 8, 24, 64])\n",
            "out multi shape torch.Size([16, 24, 512])\n",
            "input multi shape torch.Size([16, 24, 512])\n",
            "query fully connected torch.Size([16, 24, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 24, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 24, 21]) \n",
            "matmul with value torch.Size([16, 8, 24, 64])\n",
            "out multi shape torch.Size([16, 24, 512])\n",
            "input multi shape torch.Size([16, 24, 512])\n",
            "query fully connected torch.Size([16, 24, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 24, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 24, 24]) \n",
            "matmul with value torch.Size([16, 8, 24, 64])\n",
            "out multi shape torch.Size([16, 24, 512])\n",
            "input multi shape torch.Size([16, 24, 512])\n",
            "query fully connected torch.Size([16, 24, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 24, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 24, 21]) \n",
            "matmul with value torch.Size([16, 8, 24, 64])\n",
            "out multi shape torch.Size([16, 24, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [0/1]:   0%|          | 4/1813 [00:06<48:01,  1.59s/it, loss=8.31]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trg shape is torch.Size([16, 17])\n",
            "input multi shape torch.Size([16, 13, 512])\n",
            "query fully connected torch.Size([16, 13, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 13, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 13, 13]) \n",
            "matmul with value torch.Size([16, 8, 13, 64])\n",
            "out multi shape torch.Size([16, 13, 512])\n",
            "input multi shape torch.Size([16, 13, 512])\n",
            "query fully connected torch.Size([16, 13, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 13, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 13, 13]) \n",
            "matmul with value torch.Size([16, 8, 13, 64])\n",
            "out multi shape torch.Size([16, 13, 512])\n",
            "input multi shape torch.Size([16, 13, 512])\n",
            "query fully connected torch.Size([16, 13, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 13, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 13, 13]) \n",
            "matmul with value torch.Size([16, 8, 13, 64])\n",
            "out multi shape torch.Size([16, 13, 512])\n",
            "input multi shape torch.Size([16, 13, 512])\n",
            "query fully connected torch.Size([16, 13, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 13, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 13, 13]) \n",
            "matmul with value torch.Size([16, 8, 13, 64])\n",
            "out multi shape torch.Size([16, 13, 512])\n",
            "input multi shape torch.Size([16, 16, 512])\n",
            "query fully connected torch.Size([16, 16, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 16, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 16, 16]) \n",
            "matmul with value torch.Size([16, 8, 16, 64])\n",
            "out multi shape torch.Size([16, 16, 512])\n",
            "input multi shape torch.Size([16, 16, 512])\n",
            "query fully connected torch.Size([16, 16, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 16, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 16, 13]) \n",
            "matmul with value torch.Size([16, 8, 16, 64])\n",
            "out multi shape torch.Size([16, 16, 512])\n",
            "input multi shape torch.Size([16, 16, 512])\n",
            "query fully connected torch.Size([16, 16, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 16, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 16, 16]) \n",
            "matmul with value torch.Size([16, 8, 16, 64])\n",
            "out multi shape torch.Size([16, 16, 512])\n",
            "input multi shape torch.Size([16, 16, 512])\n",
            "query fully connected torch.Size([16, 16, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 16, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 16, 13]) \n",
            "matmul with value torch.Size([16, 8, 16, 64])\n",
            "out multi shape torch.Size([16, 16, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [0/1]:   0%|          | 5/1813 [00:07<45:06,  1.50s/it, loss=7.94]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trg shape is torch.Size([16, 25])\n",
            "input multi shape torch.Size([16, 19, 512])\n",
            "query fully connected torch.Size([16, 19, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 19, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 19, 19]) \n",
            "matmul with value torch.Size([16, 8, 19, 64])\n",
            "out multi shape torch.Size([16, 19, 512])\n",
            "input multi shape torch.Size([16, 19, 512])\n",
            "query fully connected torch.Size([16, 19, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 19, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 19, 19]) \n",
            "matmul with value torch.Size([16, 8, 19, 64])\n",
            "out multi shape torch.Size([16, 19, 512])\n",
            "input multi shape torch.Size([16, 19, 512])\n",
            "query fully connected torch.Size([16, 19, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 19, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 19, 19]) \n",
            "matmul with value torch.Size([16, 8, 19, 64])\n",
            "out multi shape torch.Size([16, 19, 512])\n",
            "input multi shape torch.Size([16, 19, 512])\n",
            "query fully connected torch.Size([16, 19, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 19, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 19, 19]) \n",
            "matmul with value torch.Size([16, 8, 19, 64])\n",
            "out multi shape torch.Size([16, 19, 512])\n",
            "input multi shape torch.Size([16, 24, 512])\n",
            "query fully connected torch.Size([16, 24, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 24, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 24, 24]) \n",
            "matmul with value torch.Size([16, 8, 24, 64])\n",
            "out multi shape torch.Size([16, 24, 512])\n",
            "input multi shape torch.Size([16, 24, 512])\n",
            "query fully connected torch.Size([16, 24, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 24, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 24, 19]) \n",
            "matmul with value torch.Size([16, 8, 24, 64])\n",
            "out multi shape torch.Size([16, 24, 512])\n",
            "input multi shape torch.Size([16, 24, 512])\n",
            "query fully connected torch.Size([16, 24, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 24, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 24, 24]) \n",
            "matmul with value torch.Size([16, 8, 24, 64])\n",
            "out multi shape torch.Size([16, 24, 512])\n",
            "input multi shape torch.Size([16, 24, 512])\n",
            "query fully connected torch.Size([16, 24, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 24, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 24, 19]) \n",
            "matmul with value torch.Size([16, 8, 24, 64])\n",
            "out multi shape torch.Size([16, 24, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [0/1]:   0%|          | 6/1813 [00:09<47:08,  1.57s/it, loss=8.1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trg shape is torch.Size([16, 20])\n",
            "input multi shape torch.Size([16, 14, 512])\n",
            "query fully connected torch.Size([16, 14, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 14, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 14, 14]) \n",
            "matmul with value torch.Size([16, 8, 14, 64])\n",
            "out multi shape torch.Size([16, 14, 512])\n",
            "input multi shape torch.Size([16, 14, 512])\n",
            "query fully connected torch.Size([16, 14, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 14, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 14, 14]) \n",
            "matmul with value torch.Size([16, 8, 14, 64])\n",
            "out multi shape torch.Size([16, 14, 512])\n",
            "input multi shape torch.Size([16, 14, 512])\n",
            "query fully connected torch.Size([16, 14, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 14, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 14, 14]) \n",
            "matmul with value torch.Size([16, 8, 14, 64])\n",
            "out multi shape torch.Size([16, 14, 512])\n",
            "input multi shape torch.Size([16, 14, 512])\n",
            "query fully connected torch.Size([16, 14, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 14, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 14, 14]) \n",
            "matmul with value torch.Size([16, 8, 14, 64])\n",
            "out multi shape torch.Size([16, 14, 512])\n",
            "input multi shape torch.Size([16, 19, 512])\n",
            "query fully connected torch.Size([16, 19, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 19, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 19, 19]) \n",
            "matmul with value torch.Size([16, 8, 19, 64])\n",
            "out multi shape torch.Size([16, 19, 512])\n",
            "input multi shape torch.Size([16, 19, 512])\n",
            "query fully connected torch.Size([16, 19, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 19, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 19, 14]) \n",
            "matmul with value torch.Size([16, 8, 19, 64])\n",
            "out multi shape torch.Size([16, 19, 512])\n",
            "input multi shape torch.Size([16, 19, 512])\n",
            "query fully connected torch.Size([16, 19, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 19, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 19, 19]) \n",
            "matmul with value torch.Size([16, 8, 19, 64])\n",
            "out multi shape torch.Size([16, 19, 512])\n",
            "input multi shape torch.Size([16, 19, 512])\n",
            "query fully connected torch.Size([16, 19, 512])\n",
            "Q view(batch,self.n_head,query_len,self.head_dim) torch.Size([16, 8, 19, 64])\n",
            "energy bnqk shape torch.Size([16, 8, 19, 14]) \n",
            "matmul with value torch.Size([16, 8, 19, 64])\n",
            "out multi shape torch.Size([16, 19, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-463-77321d7c0420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch [{i}/{num_epoch}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         raise RuntimeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         raise RuntimeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m             \u001b[0m_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# noqa: C416 TODO: rewrite as list(range(m))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m     \u001b[0;31m# TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kjA_1wYQd9K7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}